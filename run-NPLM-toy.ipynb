{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f063793-dbcf-446c-b0c7-08855a17c1cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob, h5py, math, time, os, json, argparse, datetime\n",
    "import numpy as np\n",
    "from FLKutils import *\n",
    "from SampleUtils import *\n",
    "\n",
    "import matplotlib as mpl\n",
    "#mpl.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as font_manager\n",
    "plt.rcParams[\"font.family\"] = \"serif\"\n",
    "plt.style.use('classic')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52d64d63-3567-44a4-a253-e626217eee31",
   "metadata": {},
   "source": [
    "# Problem setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cc228341-ec5d-41fc-88f0-923635976ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels identifying the signal classes in the dataset\n",
    "sig_labels=[3]\n",
    "# labels identifying the background classes in the dataset\n",
    "bkg_labels=[0, 1, 2]\n",
    "\n",
    "# hyper parameters of the NPLM model based on kernel methods\n",
    "## number of kernels\n",
    "M = 1000 \n",
    "\n",
    "## percentile of the distribution of pair-wise distances between reference-distributed points\n",
    "flk_sigma_perc=90 \n",
    "\n",
    "## L2 regularization coefficient\n",
    "lam =1e-6 \n",
    "\n",
    "## number of maximum iterations before the training is killed\n",
    "iterations=1000000 \n",
    "\n",
    "## number of toys to simulate \n",
    "## (multiple experiments allow you to build a statistics for the test and quantify type I and II errors)\n",
    "Ntoys = 10 \n",
    "\n",
    "## details about the save path\n",
    "folder_out = './out/'\n",
    "sig_string = ''\n",
    "if N_sig:\n",
    "    sig_string+='_SIG'\n",
    "    for s in sig_labels:\n",
    "        sig_string+='-%i'%(s)\n",
    "NP = '%s_NR%i_NB%i_NS%i_M%i_lam%s_iter%i/'%(sig_string, N_ref, N_bkg, N_sig,\n",
    "                                                  M, str(lam), iterations)\n",
    "if not os.path.exists(folder_out+NP):\n",
    "    os.makedirs(folder_out+NP)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afd32423-b17c-48e1-a0cf-44c502c9d42d",
   "metadata": {},
   "source": [
    "# Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ca90aefb-40d9-4179-85e6-e9cc7e230866",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.load('./predictions/simclr_predictions.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8c30b9a2-1b92-4aed-8200-7ae0183b5933",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['instances',\n",
       " 'dim2',\n",
       " 'dim4',\n",
       " 'dim8',\n",
       " 'dim16',\n",
       " 'dim24',\n",
       " 'dim8_embedding',\n",
       " 'dim2_embedding',\n",
       " 'dim16_embedding',\n",
       " 'dim24_embedding',\n",
       " 'dim32_embedding']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f290c0f6-9774-485e-b3b3-1b9309f71535",
   "metadata": {},
   "outputs": [],
   "source": [
    "target=a['dim8']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "aa6b1f33-6f43-4014-bad7-a61673cf6a60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4ff4e1ac-db02-453c-8844-8389a26ab589",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 2048, 4)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a['dim8_embedding'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4be34c7c-0963-40eb-b002-7f0f550b10ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "features=a['dim8_embedding'].reshape((-1, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "bb6328bf-1294-402e-8e93-4ecc0a2267d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40960, 4)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "45883964-6f80-4c8b-8f79-28bfc349e630",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40960,)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b0c118-cab1-4529-8b20-75793654cb97",
   "metadata": {},
   "outputs": [],
   "source": [
    "############ begin load data\n",
    "# This part needs to be modified according to how the predictions of your model are stored.\n",
    "# Here the predictions are saved in npz files\n",
    "print('Load data')\n",
    "folder = './predictions/simclr_predictions.npz'\n",
    "data= {}\n",
    "for file in glob.glob(folder+'/*.npz'):\n",
    "    filename = file.split('/')[-1].replace('.npz', '')\n",
    "    data[filename]= {}\n",
    "    file_load = np.load(file)\n",
    "    for k2 in file_load.files:\n",
    "        data[filename][k2] = file_load[k2]\n",
    "\n",
    "features = #...\n",
    "target = #...\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0a8c4041-719e-457f-9de5-0c01d82e6af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select SIG and BKG classes\n",
    "mask_SIG = np.zeros_like(target)\n",
    "mask_BKG = np.zeros_like(target)\n",
    "for sig_label in sig_labels:\n",
    "    mask_SIG += 1*(target==sig_label)\n",
    "for bkg_label in bkg_labels:\n",
    "    mask_BKG += 1*(target==bkg_label)\n",
    "\n",
    "features_SIG = features[mask_SIG>0]\n",
    "features_BKG = features[mask_BKG>0]\n",
    "############ end load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b66d87dd-1450-4601-9edb-83ecbc640d3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "standardize\n",
      "mean:  [-2.13186052 -2.12510567 -2.50298683 -3.32404615]\n",
      "std:  [0.96278889 0.76894639 0.7268368  0.35038829]\n"
     ]
    }
   ],
   "source": [
    "######## standardizes data\n",
    "print('standardize')\n",
    "features_mean, features_std = np.mean(features_BKG, axis=0), np.std(features_BKG, axis=0)\n",
    "print('mean: ', features_mean)\n",
    "print('std: ', features_std)\n",
    "features_BKG = standardize(features_BKG, features_mean, features_std)\n",
    "features_SIG = standardize(features_SIG, features_mean, features_std)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5bea0580-ef4f-4a3d-97e7-2eed68a5b7fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flk_sigma 4.0\n"
     ]
    }
   ],
   "source": [
    "#### compute sigma hyper parameter from data\n",
    "#### sigma is the gaussian kernels width. \n",
    "#### Following a heuristic, we set this hyperparameter to the 90% quantile of the distribution of pair-wise distances between bkg-distributed points\n",
    "#### (see below)\n",
    "#### This doesn't need modifications, but one could in principle change it (see https://arxiv.org/abs/2408.12296)\n",
    "flk_sigma = candidate_sigma(features_BKG[:2000, :], perc=flk_sigma_perc)\n",
    "print('flk_sigma', flk_sigma)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3df3afe-437c-48d0-a989-ccec8bfd40b0",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aca8082-1e2d-4334-bb10-d543cc95822e",
   "metadata": {},
   "source": [
    "## null hypothesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2e588807-e804-4c6f-9bba-a2cc2dcef75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_ref = 10000 # number of reference datapoints (mixture of non-anomalous classes)\n",
    "N_bkg = 1000 # number of backgroun datapoints in the data (mixture of non-anomalous classes present in the data)\n",
    "N_sig = 0 # number of signal datapoints in the data (mixture of anomalous classes present in the data)\n",
    "w_ref = N_bkg*1./N_ref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a3f81ae0-c650-4b07-9470-6bf79bf17c34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start running toys\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'packaging' from 'pkg_resources' (/opt/conda/lib/python3.10/site-packages/pkg_resources/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[56], line 27\u001b[0m\n\u001b[1;32m     25\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     26\u001b[0m flk_config \u001b[38;5;241m=\u001b[39m get_logflk_config(M,flk_sigma,[lam],weight\u001b[38;5;241m=\u001b[39mw_ref,\u001b[38;5;28miter\u001b[39m\u001b[38;5;241m=\u001b[39m[iterations],seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,cpu\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m---> 27\u001b[0m t, pred \u001b[38;5;241m=\u001b[39m \u001b[43mrun_toy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mt0\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mw_ref\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mflk_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mflk_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplot\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mplot_reco\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msavefig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mplot_reco\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m t0 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mappend(t0, t)\n",
      "File \u001b[0;32m~/NPLM-embedding/FLKutils.py:75\u001b[0m, in \u001b[0;36mrun_toy\u001b[0;34m(test_label, X_train, Y_train, weight, flk_config, seed, plot, verbose, savefig, output_path, df, binsrange, yrange, xlabels)\u001b[0m\n\u001b[1;32m     73\u001b[0m flk_config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mseed\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m=\u001b[39mseed \u001b[38;5;66;03m# select different centers for different toys                                                   \u001b[39;00m\n\u001b[1;32m     74\u001b[0m st_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m---> 75\u001b[0m preds \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43mY_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43mflk_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     76\u001b[0m t \u001b[38;5;241m=\u001b[39m compute_t(preds,Y_train,weight)\n\u001b[1;32m     77\u001b[0m dt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mround\u001b[39m(time\u001b[38;5;241m.\u001b[39mtime()\u001b[38;5;241m-\u001b[39mst_time,\u001b[38;5;241m2\u001b[39m)\n",
      "File \u001b[0;32m~/NPLM-embedding/FLKutils.py:46\u001b[0m, in \u001b[0;36mtrainer\u001b[0;34m(X, Y, flk_config)\u001b[0m\n\u001b[1;32m     44\u001b[0m Xtorch\u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(X)\n\u001b[1;32m     45\u001b[0m Ytorch\u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(Y)\n\u001b[0;32m---> 46\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mLogisticFalkon\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mflk_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     47\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(Xtorch, Ytorch)\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model\u001b[38;5;241m.\u001b[39mpredict(Xtorch)\u001b[38;5;241m.\u001b[39mnumpy()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/falkon/models/logistic_falkon.py:129\u001b[0m, in \u001b[0;36mLogisticFalkon.__init__\u001b[0;34m(self, kernel, penalty_list, iter_list, loss, M, center_selection, seed, error_fn, error_every, options)\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    125\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIteration list must be of same length as penalty list \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    126\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(found \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter_list), \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpenalty_list))\n\u001b[1;32m    127\u001b[0m     )\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss \u001b[38;5;241m=\u001b[39m loss\n\u001b[0;32m--> 129\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_init_cuda\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/falkon/models/model_utils.py:73\u001b[0m, in \u001b[0;36mFalkonBase._init_cuda\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_cuda_:\n\u001b[1;32m     72\u001b[0m     torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39minit()\n\u001b[0;32m---> 73\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_gpus \u001b[38;5;241m=\u001b[39m \u001b[43mdevices\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_gpus\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/falkon/utils/devices.py:203\u001b[0m, in \u001b[0;36mnum_gpus\u001b[0;34m(opt)\u001b[0m\n\u001b[1;32m    201\u001b[0m \u001b[38;5;28;01mglobal\u001b[39;00m __COMP_DATA\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(__COMP_DATA) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 203\u001b[0m     \u001b[43mget_device_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43mopt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlen\u001b[39m([c \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m __COMP_DATA \u001b[38;5;28;01mif\u001b[39;00m c \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m])\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/falkon/utils/devices.py:192\u001b[0m, in \u001b[0;36mget_device_info\u001b[0;34m(opt)\u001b[0m\n\u001b[1;32m    189\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m __COMP_DATA\n\u001b[1;32m    191\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m g \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, tcd\u001b[38;5;241m.\u001b[39mdevice_count()):\n\u001b[0;32m--> 192\u001b[0m     __COMP_DATA \u001b[38;5;241m=\u001b[39m \u001b[43m_get_gpu_device_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43mopt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m__COMP_DATA\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(__COMP_DATA) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo suitable device found. Enable option \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muse_cpu\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m if no GPU is available.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/falkon/utils/devices.py:84\u001b[0m, in \u001b[0;36m_get_gpu_device_info\u001b[0;34m(opt, g, data_dict)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;66;03m# try:\u001b[39;00m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;66;03m#     from ..cuda.cudart_gpu import cuda_meminfo\u001b[39;00m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;66;03m# except Exception as e:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;66;03m# Some of the CUDA calls in here may change the current device,\u001b[39;00m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;66;03m# this ensures it gets reset at the end.\u001b[39;00m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tcd\u001b[38;5;241m.\u001b[39mdevice(g):\n\u001b[0;32m---> 84\u001b[0m     mem_free, mem_total \u001b[38;5;241m=\u001b[39m \u001b[43mmem_get_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43mg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     85\u001b[0m     mem_used \u001b[38;5;241m=\u001b[39m mem_total \u001b[38;5;241m-\u001b[39m mem_free\n\u001b[1;32m     86\u001b[0m     \u001b[38;5;66;03m# noinspection PyUnresolvedReferences\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/falkon/c_ext/__init__.py:15\u001b[0m, in \u001b[0;36m_make_lazy_cuda_func.<locals>.call_cuda\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_cuda\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m---> 15\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_backend\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _assert_has_ext\n\u001b[1;32m     17\u001b[0m     _assert_has_ext()\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(torch\u001b[38;5;241m.\u001b[39mops\u001b[38;5;241m.\u001b[39mfalkon, name)(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/falkon/c_ext/_backend.py:19\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Optional\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcuda\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcpp_extension\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _get_build_directory, load\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_extension_path\u001b[39m(lib_name):\n\u001b[1;32m     23\u001b[0m     lib_dir \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mdirname(\u001b[38;5;18m__file__\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/cpp_extension.py:25\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtorch_version\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TorchVersion\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msetuptools\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommand\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbuild_ext\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m build_ext\n\u001b[0;32m---> 25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpkg_resources\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m packaging  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m     27\u001b[0m IS_WINDOWS \u001b[38;5;241m=\u001b[39m sys\u001b[38;5;241m.\u001b[39mplatform \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwin32\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     28\u001b[0m IS_MACOS \u001b[38;5;241m=\u001b[39m sys\u001b[38;5;241m.\u001b[39mplatform\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdarwin\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'packaging' from 'pkg_resources' (/opt/conda/lib/python3.10/site-packages/pkg_resources/__init__.py)"
     ]
    }
   ],
   "source": [
    "## run toys\n",
    "print('Start running toys')\n",
    "t0=np.array([])\n",
    "seeds = np.random.uniform(low=1, high=100000, size=(Ntoys,))\n",
    "for i in range(Ntoys):\n",
    "    seed = int(seeds[i])\n",
    "    rng = np.random.default_rng(seed=seed)\n",
    "    N_bkg_p = rng.poisson(lam=N_bkg, size=1)[0]\n",
    "    N_sig_p = rng.poisson(lam=N_sig, size=1)[0]\n",
    "    rng.shuffle(features_SIG)\n",
    "    rng.shuffle(features_BKG)\n",
    "    features_s = features_SIG[:N_sig_p, :]\n",
    "    features_b = features_BKG[:N_bkg_p+N_ref, :]\n",
    "    features  = np.concatenate((features_s,features_b), axis=0)\n",
    "\n",
    "    label_R = np.zeros((N_ref,))\n",
    "    label_D = np.ones((N_bkg_p+N_sig_p, ))\n",
    "    labels  = np.concatenate((label_D,label_R), axis=0)\n",
    "    \n",
    "    plot_reco=False\n",
    "    verbose=False\n",
    "    # make reconstruction plots every 20 toys (can be changed)\n",
    "    if not i%20:\n",
    "        plot_reco=True\n",
    "        verbose=True\n",
    "    flk_config = get_logflk_config(M,flk_sigma,[lam],weight=w_ref,iter=[iterations],seed=None,cpu=False)\n",
    "    t, pred = run_toy('t0', features, labels, weight=w_ref, seed=seed,\n",
    "                      flk_config=flk_config, output_path='./', plot=plot_reco, savefig=plot_reco,\n",
    "                      verbose=verbose)\n",
    "    \n",
    "    t0 = np.append(t0, t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "013a4164-610b-4edf-9f22-7eedfd709972",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.0.post200'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a234ca1b-a6e8-4204-b209-9a30eda0951e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'11.2'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.version.cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19cbf330-7207-4706-aea1-c1ab8db2752f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## alternative hypothesis (signal injection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f18e2700-0c02-451f-9a41-d946d169dfab",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_ref = 100000 # number of reference datapoints (mixture of non-anomalous classes)\n",
    "N_bkg = 10000 # number of backgroun datapoints in the data (mixture of non-anomalous classes present in the data)\n",
    "N_sig = 100 # number of signal datapoints in the data (mixture of anomalous classes present in the data)\n",
    "w_ref = N_bkg*1./N_ref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c70d61-b30a-4adf-b98f-9dbdf8c83dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "## run toys\n",
    "print('Start running toys')\n",
    "t1=np.array([])\n",
    "seeds = np.random.uniform(low=1, high=100000, size=(Ntoys,))\n",
    "for i in range(Ntoys):\n",
    "    seed = seeds[i]\n",
    "    rng = np.random.default_rng(seed=seed)\n",
    "    N_bkg_p = rng.poisson(lam=N_bkg, size=1)[0]\n",
    "    N_sig_p = rng.poisson(lam=N_sig, size=1)[0]\n",
    "    rng.shuffle(features_SIG)\n",
    "    rng.shuffle(features_BKG)\n",
    "    features_s = features_SIG[:N_sig_p, :]\n",
    "    features_b = features_BKG[:N_bkg_p+N_ref, :]\n",
    "    features  = np.concatenate((features_s,features_b), axis=0)\n",
    "\n",
    "    label_R = np.zeros((N_ref,))\n",
    "    label_D = np.ones((N_bkg_p+N_sig_p, ))\n",
    "    labels  = np.concatenate((label_D,label_R), axis=0)\n",
    "    \n",
    "    plot_reco=False\n",
    "    verbose=False\n",
    "    # make reconstruction plots every 20 toys (can be changed)\n",
    "    if not i%20:\n",
    "        plot_reco=True\n",
    "        verbose=True\n",
    "    flk_config = get_logflk_config(M,flk_sigma,[lam],weight=w_ref,iter=[iterations],seed=None,cpu=False)\n",
    "    t, pred = run_toy(manifold, features, labels, weight=w_ref, seed=seed,\n",
    "                      flk_config=flk_config, output_path='./', plot=plot_reco, savefig=plot_reco,\n",
    "                      verbose=verbose)\n",
    "    \n",
    "    t1 = np.append(t1, t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca3a8787-34c4-468a-8ea3-6e619557ca66",
   "metadata": {},
   "source": [
    "# Plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a882629b-455f-441e-bce1-db67bf498f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Z_score_chi2(t,df):\n",
    "    sf = chi2.sf(t, df)\n",
    "    Z  = -norm.ppf(sf)\n",
    "    return Z\n",
    "\n",
    "def Z_score_norm(t,mu, std):\n",
    "    sf = norm.sf(t, mu, std)\n",
    "    Z  = -norm.ppf(sf)\n",
    "    return Z\n",
    "\n",
    "def plot_1distribution(t, df, xmin=0, xmax=300, nbins=10, save=False, ymax=None, output_path='', save_name='', label=''):\n",
    "    '''\n",
    "    Plot the histogram of a test statistics sample (t) and the target chi2 distribution (df must be specified!). \n",
    "    The median and the error on the median are calculated in order to calculate the median Z-score and its error.\n",
    "    '''\n",
    "    plt.rcParams[\"font.family\"] = \"serif\"\n",
    "    plt.style.use('classic')\n",
    "    fig  = plt.figure(figsize=(12, 9))\n",
    "    fig.patch.set_facecolor('white')\n",
    "    # plot distribution histogram\n",
    "    bins      = np.linspace(xmin, xmax, nbins+1)\n",
    "    Z_obs     = norm.ppf(chi2.cdf(np.median(t), df))\n",
    "    t_obs_err = 1.2533*np.std(t)*1./np.sqrt(t.shape[0])\n",
    "    Z_obs_p   = norm.ppf(chi2.cdf(np.median(t)+t_obs_err, df))\n",
    "    Z_obs_m   = norm.ppf(chi2.cdf(np.median(t)-t_obs_err, df))\n",
    "    label  = 'sample %s\\nsize: %i \\nmedian: %s, std: %s\\n'%(label, t.shape[0], str(np.around(np.median(t), 2)),str(np.around(np.std(t), 2)))\n",
    "    label += 'Z = %s (+%s/-%s)'%(str(np.around(Z_obs, 2)), str(np.around(Z_obs_p-Z_obs, 2)), str(np.around(Z_obs-Z_obs_m, 2)))\n",
    "    binswidth = (xmax-xmin)*1./nbins\n",
    "    h = plt.hist(t, weights=np.ones_like(t)*1./(t.shape[0]*binswidth), color='lightblue', ec='#2c7fb8',\n",
    "                 bins=bins, label=label)\n",
    "    err = np.sqrt(h[0]/(t.shape[0]*binswidth))\n",
    "    x   = 0.5*(bins[1:]+bins[:-1])\n",
    "    plt.errorbar(x, h[0], yerr = err, color='#2c7fb8', marker='o', ls='')\n",
    "    # plot reference chi2\n",
    "    x  = np.linspace(chi2.ppf(0.0001, df), chi2.ppf(0.9999, df), 100)\n",
    "    plt.plot(x, chi2.pdf(x, df),'midnightblue', lw=5, alpha=0.8, label=r'$\\chi^2_{%i}$'%(df))\n",
    "    font = font_manager.FontProperties(family='serif', size=14) \n",
    "    plt.legend(prop=font, frameon=False)\n",
    "    plt.xlabel('t', fontsize=18, fontname=\"serif\")\n",
    "    plt.ylabel('Probability', fontsize=18, fontname=\"serif\")\n",
    "    plt.yticks(fontsize=16, fontname=\"serif\")\n",
    "    plt.xticks(fontsize=16, fontname=\"serif\")\n",
    "    if ymax !=None:\n",
    "        plt.ylim(0., ymax)\n",
    "    if save:\n",
    "        if output_path=='':\n",
    "            print('argument output_path is not defined. The figure will not be saved.')\n",
    "        else:\n",
    "            plt.savefig(output_path+ save_name+'_distribution.pdf')\n",
    "            print('saved at %s'%(output_path+ save_name+'_distribution.pdf'))\n",
    "    plt.show()\n",
    "    plt.close(fig)\n",
    "    return\n",
    "\n",
    "def plot_2distribution(t1, t2, df, xmin=0, xmax=300, ymax=None, nbins=10, save=False, output_path='', label1='1', label2='2', save_name='', print_Zscore=True):\n",
    "    '''\n",
    "    Plot the histogram of a test statistics sample (t) and the target chi2 distribution (df must be specified!).\n",
    "    The median and the error on the median are calculated in order to calculate the median Z-score and its error.\n",
    "    '''\n",
    "    plt.rcParams[\"font.family\"] = \"serif\"\n",
    "    plt.style.use('classic')\n",
    "    fig  = plt.figure(figsize=(12, 9))\n",
    "    fig.patch.set_facecolor('white')\n",
    "    # plot distribution histogram\n",
    "    bins      = np.linspace(xmin, xmax, nbins+1)\n",
    "    binswidth = (xmax-xmin)*1./nbins\n",
    "    # t1\n",
    "    Z_obs     = Z_score_chi2(np.median(t1), df)\n",
    "    t_obs_err = 1.2533*np.std(t1)*1./np.sqrt(t1.shape[0])\n",
    "    Z_obs_p   = Z_score_chi2(np.median(t1)+t_obs_err, df)\n",
    "    Z_obs_m   = Z_score_chi2(np.median(t1)-t_obs_err, df)\n",
    "    label  = '%s \\nsize: %i\\nmedian: %s, std: %s\\n'%(label1, t1.shape[0], str(np.around(np.median(t1), 2)),str(np.around(np.std(t1), 2)))\n",
    "    if print_Zscore:\n",
    "        label += 'asymptotic Z = %s (+%s/-%s)'%(str(np.around(Z_obs, 2)), str(np.around(Z_obs_p-Z_obs, 2)), str(np.around(Z_obs-Z_obs_m, 2)))\n",
    "    \n",
    "    h = plt.hist(t1, weights=np.ones_like(t1)*1./(t1.shape[0]*binswidth), color='lightblue', ec='#2c7fb8',\n",
    "                 bins=bins, label=label)\n",
    "    err = np.sqrt(h[0]/(t1.shape[0]*binswidth))\n",
    "    x   = 0.5*(bins[1:]+bins[:-1])\n",
    "    plt.errorbar(x, h[0], yerr = err, color='#2c7fb8', marker='o', ls='')\n",
    "    max1 = np.max(h[0])\n",
    "    # t2\n",
    "    Z_obs     = Z_score_chi2(np.median(t2), df)\n",
    "    t_obs_err = 1.2533*np.std(t2)*1./np.sqrt(t2.shape[0])\n",
    "    Z_obs_p   = Z_score_chi2(np.median(t2)+t_obs_err, df)\n",
    "    Z_obs_m   = Z_score_chi2(np.median(t2)-t_obs_err, df)\n",
    "    t_empirical = np.sum(1.*(t1>np.mean(t2)))*1./t1.shape[0]\n",
    "    empirical_lim = '='\n",
    "    if t_empirical==0:\n",
    "        empirical_lim='>'\n",
    "        t_empirical = 1./t1.shape[0]\n",
    "    t_empirical_err = t_empirical*np.sqrt(1./np.sum(1.*(t1>np.mean(t2))+1./t1.shape[0]))\n",
    "    Z_empirical = norm.ppf(1-t_empirical)\n",
    "    Z_empirical_m = norm.ppf(1-(t_empirical+t_empirical_err))\n",
    "    Z_empirical_p = norm.ppf(1-(t_empirical-t_empirical_err))\n",
    "                                          \n",
    "    label  = '%s \\nsize: %i\\nmedian: %s, std: %s\\n'%(label2, t2.shape[0], str(np.around(np.median(t2), 2)),str(np.around(np.std(t2), 2)))\n",
    "    if print_Zscore:\n",
    "        label += 'asymptotic Z = %s (+%s/-%s) \\n'%(str(np.around(Z_obs, 2)), str(np.around(Z_obs_p-Z_obs, 2)), str(np.around(Z_obs-Z_obs_m, 2)))\n",
    "        label += 'empirical Z %s %s (+%s/-%s)'%(empirical_lim, str(np.around(Z_empirical, 2)), str(np.around(Z_empirical_p-Z_empirical, 2)), str(np.around(Z_empirical-Z_empirical_m, 2)))\n",
    "    h = plt.hist(t2, weights=np.ones_like(t2)*1./(t2.shape[0]*binswidth), color='#8dd3c7', ec='seagreen',\n",
    "                 bins=bins, label=label)\n",
    "    err = np.sqrt(h[0]/(t2.shape[0]*binswidth))\n",
    "    x   = 0.5*(bins[1:]+bins[:-1])\n",
    "    plt.errorbar(x, h[0], yerr = err, color='seagreen', marker='o', ls='')\n",
    "    max2 = np.max(h[0])\n",
    "    # plot reference chi2\n",
    "    x  = np.linspace(chi2.ppf(0.0001, df), chi2.ppf(0.9999, df), 100)\n",
    "    plt.plot(x, chi2.pdf(x, df),'midnightblue', lw=5, alpha=0.8, label=r'$\\chi^2_{%i}$'%(df))\n",
    "    font = font_manager.FontProperties(family='serif', size=20) #weight='bold', style='normal', \n",
    "    plt.legend(ncol=1, loc='upper right', prop=font, frameon=False)\n",
    "    plt.xlabel('$t$', fontsize=32, fontname=\"serif\")\n",
    "    plt.ylabel('Probability', fontsize=32, fontname=\"serif\")\n",
    "    plt.ylim(0., 1.2*np.maximum(max1, max2))#np.max(chi2.pdf(x, df))*1.3)\n",
    "    if ymax !=None:\n",
    "        plt.ylim(0., ymax)\n",
    "    plt.yticks(fontsize=22, fontname=\"serif\")\n",
    "    plt.xticks(fontsize=22, fontname=\"serif\")\n",
    "    if save:\n",
    "        if output_path=='':\n",
    "            print('argument output_path is not defined. The figure will not be saved.')\n",
    "        else:\n",
    "            plt.savefig(output_path+ save_name+'_2distribution.pdf')\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    return #[Z_obs, Z_obs_p, Z_obs_m], [Z_empirical, Z_empirical_p, Z_empirical_m]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b9be9ac-f95d-4f6d-9b9b-88a42551e188",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot null distribution\n",
    "plot_1distribution(t0, df=np.mean(t0), xmin=0.9*np.min(t0), xmax=60, nbins=16, save=False, ymax=None, output_path='', save_name='', label=k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd6980b0-9706-4647-842c-4cc4ebcca266",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot alternative vs null distributions\n",
    "plot_2distribution(t0, t1, df=np.mean(t0), xmin=np.min(t0), xmax=np.max(t1)*1.1, #ymax=0.03, \n",
    "                   nbins=19, label1='REF', label2='BKG+SIG', print_Zscore=True,\n",
    "                   save=False, output_path=folders[k], save_name='')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
